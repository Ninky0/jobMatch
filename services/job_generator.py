from schemas.job import JobInput, JobOutput
from embed_matching import embed_matching
from utils.prompt_builder import task_prompt
from utils.text_utils import extract_section


# ğŸ”¹ LLMì„ í˜¸ì¶œí•˜ì—¬ êµ¬ì¸ê³µê³  ì´ˆì•ˆì„ ìƒì„±í•˜ëŠ” ì„œë¹„ìŠ¤ í•¨ìˆ˜
def llm_generate_job_posting(input_data: JobInput, pipe) -> JobOutput:
    # ì§ì¢… ì˜ˆì¸¡ (10ê°œ)
    jikjong_preds = embed_matching(input_data.job_description)
    main_job = ', '.join(jikjong_preds[:5])
    sub_job = ', '.join(jikjong_preds[5:])

    # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    prompt_input = """
    (í”„ë¡¬í”„íŠ¸)
    """.format(
        input_data.company_intro,
        input_data.job_description,
        main_job,
        sub_job
    )

    # LLM ì‹¤í–‰
    task_outputs, task_prompt_len = task_prompt(prompt_input, pipe)
    output = task_outputs[0]['generated_text'][task_prompt_len:]

    # ì¶œë ¥ ì„¹ì…˜ë³„ íŒŒì‹±
    return JobOutput(
        job_title=extract_section(output, "<ê³µê³  ì œëª©>"),
        recommended_occupation_main=extract_section(output, "<ëª¨ì§‘ ì§ì¢…>"),
        recommended_occupation_sub=extract_section(output, "<ê´€ë ¨ ì§ì¢…>"),
        recommended_job=extract_section(output, "<ëª¨ì§‘ ì§ë¬´>"),
        job_intro=extract_section(output, "<ì§ë¬´ ì†Œê°œ>"),
        main_tasks=extract_section(output, "<ì£¼ìš” ì—…ë¬´>"),
        preferred_qualifications=extract_section(output, "<ìš°ëŒ€ ì‚¬í•­>"),
        search_keywords=extract_section(output, "<ê²€ìƒ‰í‚¤ì›Œë“œ>")
    )
